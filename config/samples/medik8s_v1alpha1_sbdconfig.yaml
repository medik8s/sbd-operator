# SBDConfig Sample Configuration
#
# This is a sample configuration for the SBD (STONITH Block Device) operator.
# The SBD operator provides watchdog-based fencing for Kubernetes clusters
# to ensure high availability through automatic node remediation.
#
# For comprehensive documentation, see: docs/sbdconfig-user-guide.md

apiVersion: medik8s.medik8s.io/v1alpha1
kind: SBDConfig
metadata:
  labels:
    app.kubernetes.io/name: sbd-operator
    app.kubernetes.io/managed-by: kustomize
  name: sbdconfig-sample
spec:
  # Example configuration using shared storage for multi-node clusters
  sharedStorageClass: "shared-storage-class"
  
  # Watchdog configuration
  sbdWatchdogPath: "/dev/watchdog"
  watchdogTimeout: "60s"
  petIntervalMultiple: 4
  
  # Node selection - run on worker nodes only
  nodeSelector:
    node-role.kubernetes.io/worker: ""
  
  # Timing configuration
  staleNodeTimeout: "2h"
  iotimeout: "5s"
  rebootMethod: "systemctl-reboot"
  sbdTimeoutSeconds: 45
  sbdUpdateInterval: "3s"
  peerCheckInterval: "4s"
  
  # Container configuration
  image: "quay.io/medik8s/sbd-agent:latest"
  imagePullPolicy: "IfNotPresent"
  
  # Logging
  logLevel: "info"
  
  # ========================================================================
  # MULTIPLE SBDCONFIG SUPPORT (NEW in v1.1+)
  # ========================================================================
  #
  # The SBD operator now supports multiple SBDConfig resources in the same namespace!
  # This enables advanced deployment scenarios like A/B testing, gradual rollouts,
  # and different configurations for different teams.
  #
  # KEY FEATURES:
  # - Shared service account across all SBDConfigs in a namespace
  # - Separate DaemonSets with unique names for each SBDConfig
  # - Independent configurations (images, timeouts, node selectors, etc.)
  # - Automatic cleanup when SBDConfigs are deleted
  #
  # RESOURCE NAMING:
  # - Service Account: sbd-agent (shared across all SBDConfigs in namespace)
  # - DaemonSet: sbd-agent-{sbdconfig-name} (unique per SBDConfig)
  # - ClusterRoleBinding: sbd-agent-{namespace}-{sbdconfig-name} (globally unique)
  #
  # EXAMPLE USAGE:
  # kubectl apply -f production-sbd.yaml -f canary-sbd.yaml
  # kubectl get sbdconfig -n my-app
  # kubectl get daemonset -n my-app -l app=sbd-agent
  #
  # ========================================================================
  # CONFIGURATION EXAMPLES
  # ========================================================================
  #
  # Basic Production Configuration (image auto-derived from operator):
  # -------------------------------------------------------------------
  # spec:
  #   staleNodeTimeout: "30m"
  #
  # Production with Custom Image:
  # -----------------------------
  # spec:
  #   image: "quay.io/medik8s/sbd-agent:latest"
  #   staleNodeTimeout: "30m"
  #
  # Multiple Configurations in Same Namespace:
  # ------------------------------------------
  # # Production config
  # metadata:
  #   name: production-sbd
  #   namespace: my-app
  # spec:
  #   image: "quay.io/medik8s/sbd-agent:latest"
  #   imagePullPolicy: "IfNotPresent"
  # ---
  # # Canary config  
  # metadata:
  #   name: canary-sbd
  #   namespace: my-app
  # spec:
  #   image: "quay.io/medik8s/sbd-agent:latest"
  #   imagePullPolicy: "Always"
  #   nodeSelector:
  #     canary: "true"
  #
  # High-Availability Configuration:
  # --------------------------------
  # spec:
  #   sbdWatchdogPath: "/dev/watchdog1"
  #   staleNodeTimeout: "2h"
  #
  # Development/Testing Configuration:
  # ----------------------------------
  # spec:
  #   imagePullPolicy: "Always"
  #   staleNodeTimeout: "5m"
  #
  # Note: Each SBDConfig creates its own DaemonSet in the specified namespace.
  # Multiple SBDConfigs in the same namespace share the service account but
  # have separate DaemonSets and configurations.
  #
  # ========================================================================
  # DEPLOYMENT COMMANDS
  # ========================================================================
  #
  # Apply configuration:
  #   kubectl apply -f medik8s_v1alpha1_sbdconfig.yaml
  #
  # Check status:
  #   kubectl get sbdconfig
  #   kubectl describe sbdconfig sbdconfig-sample
  #
  # Monitor deployment:
  #   kubectl get pods -n <namespace>
  #   kubectl logs -n <namespace> -l app=sbd-agent
  #   (Replace <namespace> with the namespace where you created the SBDConfig)
  #
  # ========================================================================
  # OPENSHIFT SECURITY CONTEXT CONSTRAINTS (SCC) MANAGEMENT
  # ========================================================================
  #
  # The SBD operator automatically manages OpenShift SecurityContextConstraints
  # when deployed on OpenShift clusters. The controller will:
  #
  # 1. Detect if running on OpenShift platform
  # 2. Check for the required SCC: sbd-operator-sbd-agent-privileged
  # 3. Automatically update the SCC to grant permissions to service accounts
  #    in any namespace where SBDConfig resources are deployed
  #
  # Example: If you create an SBDConfig in namespace "my-app", the operator
  # will automatically add "system:serviceaccount:my-app:sbd-agent" to the
  # SCC users list, allowing pods to start with required privileges.
  #
  # Manual SCC management (if needed):
  #   # Check SCC status
  #   oc get scc sbd-operator-sbd-agent-privileged -o yaml
  #   
  #   # Manually add service account (normally automatic)
  #   oc adm policy add-scc-to-user sbd-operator-sbd-agent-privileged \
  #     system:serviceaccount:my-namespace:sbd-agent
  #
  # Note: The base SCC must be installed via the OpenShift installer:
  #   make build-openshift-installer
  #   kubectl apply -f dist/install-openshift.yaml
  #
  # ========================================================================